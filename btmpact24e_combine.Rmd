---
title: "Combine OpenAlex and Altmetric data"
author: "Anonymized for peer review (NC)"
reviewer: "Anonymized for peer review (JT)"
output: word_document
editor_options: 
  chunk_output_type: console
---
This code combines OpenAlex and Altmetric data.

# Configure environment
```{r libraries}
# load libraries
library('tidyverse')
library('here')

# specify directory
i_am('btmpact24e_combine.Rmd')
```

# Open and merge OpenAlex datasets
## Open and identify datasets
```{r}
# AI data
DF.ai <- 
  readRDS(file = 'data/cgpt/btmpact24e_data_binded_cgpt.Rds')

# COVID data
DF.covid <- 
  readRDS(file = 'data/covid/btmpact24e_data_binded_covid.Rds')
  
# terrorism data
DF.terror <- 
  readRDS(file = 'data/terrorism/btmpact24e_data_raw_terrorism.Rds')
```

## Prepare OpenAlex search data
### AI
```{r}
DF.ai <- 
  DF.ai %>% 
  # select distinct records
  distinct(id,
           .keep_all = T) %>% 
  distinct(doi,
           .keep_all = T) %>% 
  
  # focus on records published after the release of Chat GPT (2022-11-30)
  mutate(publication_date = as.Date(publication_date)) %>% 
  filter(publication_date > "2022-11-30") %>% 
  
  # create dataset identifier
  mutate(dataset = 'ai') %>% 
  
  # identify number of authors 
  ## remove instances with no authorship info
  filter(!is.na(author)) %>%
  
  ## identify number of authors by examining how many author rows are in each record
  rowwise() %>% 
  mutate(authors.n = nrow(author)) %>% 
  ungroup() %>% 
  
  # select relevant variables
  select(id, authors.n, 
         publication_date, cited_by_count,
         dataset)
```

### COVID
```{r}
DF.covid <- 
  DF.covid %>%
  # select distinct records
  distinct(id,
           .keep_all = T) %>% 
  distinct(doi,
           .keep_all = T) %>% 
  
  # focus on records published after the beginning of COVID-19 (first cases: Nov 2019)
  mutate(publication_date = as.Date(publication_date)) %>% 
  filter(publication_date > "2019-11-01") %>% 
  
  # create dataset identifier
  mutate(dataset = 'covid') %>% 
  
  # identify number of authors 
  ## remove instances with no authorship info
  filter(!is.na(author)) %>%
  
  ## identify number of authors by examining how many author rows are in each record
  rowwise() %>% 
  mutate(authors.n = nrow(author)) %>% 
  ungroup() %>% 
  
  # select relevant variables
  select(id, authors.n, 
         publication_date, cited_by_count,
         dataset)
```

### terrorism
```{r}
DF.terror <- 
  DF.terror %>% 
  # select distinct records
  distinct(id,
           .keep_all = T) %>% 
  distinct(doi,
           .keep_all = T) %>% 
  
  # focus on records published after 2001-09-11
  mutate(publication_date = as.Date(publication_date)) %>% 
  filter(publication_date > "2001-09-11") %>% 
  
  # create dataset identifier
  mutate(dataset = 'terror') %>% 
  
  # identify number of authors 
  ## remove instances with no authorship info
  filter(!is.na(author)) %>%
  
  ## identify number of authors by examining how many author rows are in each record
  rowwise() %>% 
  mutate(authors.n = nrow(author)) %>% 
  ungroup() %>% 
  
  # select relevant variables
  select(id, authors.n, 
         publication_date, cited_by_count,
         dataset)
```

### Combine and export datasets
```{r}
# combine 
DF.oa <- 
  rbind(DF.ai,
        DF.covid,
        DF.terror)

# export
# DF.oa %>% 
#   saveRDS('data/combined/DF.oa.combined.Rds')

# delete vestigial
rm(DF.ai, DF.covid, DF.terror)
```

## Prepare Altmetrics datasets
### AI
```{r}
# identifiers included in btmpact24e_data_doi_ai.csv
DF.ident <- 
  read.csv(here("data",
                "cgpt",
                "btmpact24e_data_doi_cgpt.csv")) %>% 
  rename(DOI = doi) %>% 
  mutate(DOI = str_replace(string = DOI,
                           pattern = "https://doi.org/",
                           replacement = "")) %>% 
  
  # select distinct records
  distinct(DOI,
           .keep_all = T) %>% 
  
  # select the identifiers that will link all the datasets
  select(id, DOI)

# open Altmetric raw data
DF.alt <- read.csv(here("data", 
                        "cgpt",
                        "btmpact24e_altmetric_cgpt.csv")) %>% 
  
  # select distinct records
  distinct(DOI,
           .keep_all = T) 

# connect the Altmetric dataset and identifiers
DF.alt.ai <- 
  left_join(x = DF.alt,
            y = DF.ident,
            by = "DOI")

# delete vestigial
rm(DF.alt, DF.ident)
```

### COVID
```{r}
# identifiers included in btmpact24e_data_doi_covid.csv
DF.ident <- read.csv(here("data",
                          "covid",
                          "btmpact24e_data_doi_covid.csv")) %>% 
  rename(DOI = doi) %>% 
  mutate(DOI = str_replace(string = DOI,
                           pattern = "https://doi.org/",
                           replacement = "")) %>% 
  
  # select distinct records
  distinct(DOI,
           .keep_all = T) %>% 
  
  # select the identifiers that will link all the datasets
  select(id, DOI)

# open Altmetric raw data
DF.alt <- read.csv(here("data", 
                        "covid",
                        "btmpact24e_altmetric_covid.csv")) %>% 
  
    
  # select distinct records
  distinct(DOI,
           .keep_all = T)

# connect the Altmetric dataset and identifiers
DF.alt.covid <- 
  left_join(x = DF.alt,
            y = DF.ident,
            by = "DOI")

# delete vestigial
rm(DF.alt, DF.ident)
```

### terrorism
```{r}
# identifiers included in btmpact24e_data.doi.csv
DF.ident <- read.csv(here("data",
                          "terrorism",
                          "btmpact24e_data_doi_terrorism.csv")) %>% 
  rename(DOI = doi) %>% 
  mutate(DOI = str_replace(string = DOI,
                           pattern = "https://doi.org/",
                           replacement = "")) %>% 
  
  # select the identifiers that will link all the datasets
  select(id, DOI)

# open Altmetric raw data
DF.alt <- read.csv(here("data", 
                        "terrorism",
                        "btmpact24e _altmetric_data_terrorism.csv"))

# connect the Altmetric dataset and identifiers
DF.alt.terror <- 
  left_join(x = DF.alt,
            y = DF.ident,
            by = "DOI")

# delete vestigial
rm(DF.alt, DF.ident)
```

### Combine, process, and export datasets
```{r}
DF.alt <- 
  # combine 
  rbind(DF.alt.ai, 
        DF.alt.covid,
        DF.alt.terror) %>% 
  
  # calculate news and general population mentions
  mutate(news = News.mentions + Blog.mentions,
         gen = X.mentions + Facebook.mentions,
         policy = Policy.mentions) %>% 
  
  # select relevant variables
  select(id, news, policy)

# export
DF.alt %>% 
  saveRDS('data/combined/DF.alt.combined.Rds')

# delete vestigial
rm(DF.alt.ai, DF.alt.covid, DF.alt.terror)
```

# Combine OpenAlex and Altmetrics
```{r}
# combine
DF <- 
  left_join(DF.oa,
            DF.alt %>% distinct(id, .keep_all = T),
            by = "id")

# export
DF %>% 
  saveRDS('data/combined/DF.full.combined.Rds')

# delete vestigial
rm(DF.oa, DF.alt, DF.field)
```
