---
title: "Scramble proprietary Altmetric data for sharing"
author: "Anonymized for peer review (NC)"
reviewer: "Anonymized for peer review (JT)"
output: word_document
editor_options: 
  chunk_output_type: console
---
This code scrambles proprietary Altmetric data for sharing

# Setup
```{r set.env}
# specify data directory
data_dir <- Sys.getenv("data_dir")

# source setup file
source('setup.R')
```

# Raw data: Import and prep Altmetric data
## ChatGPT
```{r}
alt.cgpt <- 
  # open
  read.csv(file.path(data_dir, 
                     "cgpt", 
                     "btmobile25a_altmetric_cgpt.csv")) %>% 
  
  # select relevant variables
  select(DOI, News.mentions, Blog.mentions, 
         Policy.mentions, X.mentions, Facebook.mentions)
```

## COVID-19
```{r}
alt.covid <-
  # open
  read.csv(file.path(data_dir, 
                     "covid", 
                     "btmobile25a_altmetric_covid.csv")) %>% 
  
  # select relevant variables
  select(DOI, News.mentions, Blog.mentions, 
         Policy.mentions, X.mentions, Facebook.mentions)
```

## Terrorism
```{r}
alt.terror <-
  # open
  read.csv(file.path(data_dir, 
                     "terrorism", 
                     "btmobile25a_altmetric_terrorism.csv")) %>% 
  
  # select relevant variables
  select(DOI, News.mentions, Blog.mentions, 
         Policy.mentions, X.mentions, Facebook.mentions)

```

# Raw data: Scramble, add random noise, and re-export Altmetric data
## ChatGPT
```{r}
alt.cgpt <-
  alt.cgpt %>% 
  
  # randomly reorder each key outcome -- and add noise
  mutate(across(c("News.mentions", "Blog.mentions", 
                  "Policy.mentions",  "X.mentions", 
                  "Facebook.mentions"), 
                # randomly sample (sample) and add uniform noise (runif)
                ~ sample(.) + runif(n = nrow(alt.cgpt), 
                                    max = 10)
                )
         )

# export
alt.cgpt %>% 
  write.csv(file.path(data_dir,
                      "cgpt", 
                      "btmobile25a_altmetric_cgpt_scrambled.csv"),
            row.names = F)
```

## COVID-19
```{r}
alt.covid <-
  alt.covid %>% 
  
  # randomly reorder each key outcome -- and add noise
  mutate(across(c("News.mentions", "Blog.mentions", 
                  "Policy.mentions",  "X.mentions", 
                  "Facebook.mentions"), 
                # randomly sample (sample) and add noise (runif)
                ~ sample(.) + runif(n = nrow(alt.covid), 
                                    max = 10)
                )
         )

# export
alt.covid %>% 
  write.csv(file.path(data_dir,
                      "covid", 
                      "btmobile25a_altmetric_covid_scrambled.csv"),
            row.names = F)
```

## Terrorism
```{r}
alt.terror <-
  alt.terror %>% 
  
  # randomly reorder each key outcome -- and add noise
  mutate(across(c("News.mentions", "Blog.mentions", 
                  "Policy.mentions",  "X.mentions", 
                  "Facebook.mentions"), 
                # randomly sample (sample) and add uniform noise (runif)
                ~ sample(.) + runif(n = nrow(alt.terror), 
                                    max = 10)
                )
         )

# export
alt.terror %>% 
  write.csv(file.path(data_dir,
                      "terrorism", 
                      "btmobile25a_altmetric_terrorism_scrambled.csv"),
            row.names = F)
```

```{r}
# remove raw data from environment
rm(alt.cgpt, alt.covid, alt.terror)
```

# Processed data: Import and prep datasets with Altmetric data
## DF.alt.combined.Rds
```{r}
# open
DF.alt.combined <-
  readRDS(file.path(data_dir,
                    'combined',
                    'DF.alt.combined.Rds')
          ) 

# randomly reorder each key outcome -- and add noise
DF.alt.combined <- 
  DF.alt.combined %>% 
  mutate(across(c("News.mentions" : "Number.of.Dimensions.citations",
                  "news" : "policy"), 
                # randomly sample (sample) and add uniform noise (runif)
                ~ sample(.) + runif(n = nrow(DF.alt.combined), 
                                    max = 10)
                )
         )

# re-export
DF.alt.combined %>% 
  saveRDS(file.path(data_dir,
                    'combined',
                    'DF.alt.combined.scrambled.Rds')
          )

# remove
rm(DF.alt.combined)
```

## DF.full.combined.Rds
```{r}
# open
DF.full.combined <-
  readRDS(file.path(data_dir,
                    'combined',
                    'DF.full.combined.Rds')
          ) 

# randomly reorder each key outcome -- and add noise
DF.full.combined <- 
  DF.full.combined %>% 
  mutate(across(c("News.mentions" : "Number.of.Dimensions.citations",
                  "news" : "policy"), 
                # randomly sample (sample) and add uniform noise (runif)
                ~ sample(.) + runif(n = nrow(DF.full.combined), 
                                    max = 10)
                )
         )

# re-export
DF.full.combined %>% 
  saveRDS(file.path(data_dir,
                    'combined',
                    'DF.full.combined.scrambled.Rds')
          )

rm(DF.full.combined)
```

# DF.full.combined.processed.Rds
```{r}
# open file
DF <- 
  readRDS(file.path(data_dir,
                    'combined',
                    'DF.full.combined.processed.Rds')
          )

# add noise
DF <- DF %>% 
  select(id, authors.n, dataset,
         cited_by_count, news, policy, speed,
         citation.per, news.per, policy.per, speed.per) %>% 
  
  # add random noise to raw values
  mutate(
    across(c(cited_by_count, news, policy, speed), 
           ~ . + rnorm(n(), 
                       mean = 0, 
                       sd = 10)
           )
         ) %>% 
  
  # add random noise to percentile variables
  mutate(
    across(c(citation.per, news.per, policy.per, speed.per), 
           ~ . + rnorm(n(), 
                       mean = 0, 
                       sd = 1)
           )
         )

# export
saveRDS(DF,
        file.path(data.dir,
                  'combined',
                  'DF.full.combined.processed.noise.Rds')
        )
```

